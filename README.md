# MVP: RAG-агент для 3-й линии поддержки

Локальный RAG-помощник для быстрого поиска похожих инцидентов Naumen на основе тикетов из CSV/XLSX. Все компоненты работают оффлайн на CPU и используют open-source стек.

## Возможности
- Загрузка тикетов из CSV/XLSX (обязательно поля `ID`, `Описание`, `Решение`; опционально `Дата`, `Статус`, `Тип`).
- Очистка HTML/технического шума и склейка «Описание + Решение».
- Разбиение на чанки по 500 символов с перекрытием.
- Построение эмбеддингов с помощью `sentence-transformers/all-MiniLM-L6-v2` (можно заменить на E5-small).
- Хранение векторного индекса FAISS + payload с идентификаторами тикетов.
- CLI для индексации и поиска похожих инцидентов.

## Быстрый старт
### 1) Установка окружения
```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### 2) Индексация тикетов
На вход подаётся CSV/XLSX c колонками:
- `ID` — идентификатор тикета (обязательно)
- `Описание` — текст обращения
- `Решение` — текст решения
- `Дата`, `Статус`, `Тип` — необязательно

Если экспорт из Naumen содержит другие заголовки, они автоматически сопоставляются:
- `Номер запроса` → `ID`
- `Описание` → `Описание`
- `Описание решения` → `Решение`
- `Дата/время регистрации` → `Дата`
- `Текущий статус` → `Статус`
- `Вид запроса` → `Тип`

Пример индексирования демо-файла:
```bash
python -m rag_agent.ingest \
  --input data/sample_tickets.csv \
  --output data/index \
  --model sentence-transformers/all-MiniLM-L6-v2 \
  --chunk-size 500 \
  --chunk-overlap 50
```
В результате появятся файлы `index.faiss`, `metadata.jsonl` и `config.json` в папке `data/index`.

### 3) Поиск похожих тикетов
```bash
python -m rag_agent.query \
  --index data/index \
  --query "Ошибка авторизации в личном кабинете" \
  --top-k 5
```
Выводит топ-N релевантных чанков с привязкой к `ticket_id` и `chunk_id`, готовых для подстановки в RAG-промпт.

## Архитектура
- **Эмбеддинги**: `sentence-transformers` (по умолчанию `all-MiniLM-L6-v2`).
- **Векторное хранилище**: локальный FAISS IndexFlatIP с нормализацией (косинусное сходство).
- **Метаданные**: `metadata.jsonl` с полями `ticket_id`, `chunk_id`, `text`, `source_fields`.
- **Конфигурация**: `config.json` (модель, размерность, параметры чанков).

## Формат payload для RAG
Каждый найденный чанк содержит:
```json
{
  "ticket_id": "12345",
  "chunk_id": 0,
  "text": "...",
  "source_fields": {
    "date": "2024-01-10",
    "status": "Закрыт",
    "type": "Инцидент"
  }
}
```

## Пример интеграции в промпт
```text
Вы оператор 3-й линии. Используйте контекст ниже, чтобы ответить на вопрос. Указывайте ID тикетов.

Вопрос: <вопрос оператора>

Контекст:
- [ID=<ticket_id> #<chunk_id>] <текст чанка>
...
```

## Локальная работа и замены
- Для полностью оффлайн-окружения скачайте модель заранее: `python -m sentence_transformers.download sentence-transformers/all-MiniLM-L6-v2`.
- Модель можно заменить на `intfloat/multilingual-e5-small` — укажите её через флаг `--model` при индексации и поиске.
- Вместо FAISS можно подключить Qdrant: реализуйте адаптер в `rag_agent/pipeline.py` по аналогии с FAISS (класс `VectorStore`).

## Структура репозитория
```
rag_agent/
  pipeline.py      # функции очистки, чанкинга, эмбеддинга, работы с FAISS
  ingest.py        # CLI для индексации
  query.py         # CLI для поиска
  cli.py           # объединённый интерфейс (опционально)
```

## Ограничения и будущая работа
- Нет веб-UI; добавление Streamlit/Gradio возможно поверх CLI.
- Ответы сейчас без генерации LLM; интеграция любой локальной модели возможна после retrieval.
```
